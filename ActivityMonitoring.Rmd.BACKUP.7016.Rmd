---
<<<<<<< HEAD
title: "Analysis of Activity Monitoring Data"
=======
title: "ActivityMonitoring"
>>>>>>> master
author: "Zinat Wali"
date: "Sunday, August 24, 2014"
output: html_document
---

<<<<<<< HEAD
```{r echo=FALSE, results='hide'}
library(caret)
library(randomForest)
```

## Introduction

This document describes an analysis of data acquired from Personal Activity Monitors. Data is sourced from a group of individuals performing barbell lifts. The goal of the analysis was to predict if a person is doing the lifting correctly or incorrectly by looking at the reading of the individuals activity monitors.

## Data Details

Data is sourced from the website http://groupware.les.inf.puc-rio.br/har. The data comes in two different sets clearly distinguished for training and testing.  So the first task is to read the data into local files. From there, they are then loaded into memory.

```{r cache=TRUE, results='hide'}
download.file('http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', destfile='training.csv')
training <- read.csv('training.csv')

download.file('http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv', destfile='test.csv')
test <- read.csv('test.csv')
```

The data is then copied into new data frames. The original ones are kept for reference and fallback.
=======
```{r}
library(caret)
```


```{r cache=TRUE}
training <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')

test <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
```


The training data is then copied into another data frame. The original one is kept for reference and fallback.
>>>>>>> master

```{r cache=TRUE}
inTraining <- training
inTesting <- test
```


<<<<<<< HEAD
## Understanding the structure of data and Pre-processing

Each of the datasets has got 160 columns. They are identical in the training and test data set. 

The target variable is contained in the column 'classe'. It is a factor type with five different levels -

```{r}
levels(inTraining$classe)
```


After some manual observation and walk-throughs,it is prominent that the readings from the monitors are contained in the columns 8 to 160. The next step is clean up the data sets of all those feature columns that are either not monitor readings or monitor readings but undefined(NA) or blank for all the observations.
=======
removing irrelevant features...
>>>>>>> master

```{r}
LL <- c(1:7)

for(i in 8:ncol(inTraining))
{
  if(sum(!is.na(inTraining[, i]) && inTraining[,i] != '') == 0)
  {
    LL <- append(LL, i)
  }
}

inTraining <- inTraining[, -LL]
<<<<<<< HEAD
inTesting <- inTesting[, -LL]

dim(inTraining)
dim(inTesting)

```

This leads to much neater and compact dataset.

## Partitioning the training data

As the data is now free of all irrelevant features, the next step is to partition the training set into training and test sub sets.


```{r}

allInTraining <- inTraining

partitionRule <- createDataPartition(allInTraining$classe, p = 0.9, list=FALSE)

trainingSubSet <- allInTraining[partitionRule, ]
testingSubSet <- allInTraining[-partitionRule,]


```


## Choosing a model

For doing the prediction, a model is required. In this step, the model is built. A few differnt algorithms are tried. 

The first attempt is gbm which turns to be pretty accurate but comparatively slower.

```{r eval=FALSE}
gbmFit <- train(classe ~., method = "gbm", data=trainingSubSet)
pGBM <- predict(gbmFit, newdata=testingSubSet)
accuracyGBM <- sum(pGBM == testingSubSet$classe) / nrow(testingSubSet)
```

Although later it was found that calling gbm() directly instead of using caret can be much faster.

The next attempt is svc. It is much faster but not so accurate. 

```{r eval=FALSE}
svmFit <- train(classe ~., method = "svm", data=trainingSubSet)
pSVM <- predict(svmFit, newdata=testingSubSet)
sum(pSVM == testingSubSet$classe)
```

The next attempt is Random Forest. It seems to be a winner in all respects.

```{r cache=TRUE}
rfFit <- randomForest(trainingSubSet[, -53], trainingSubSet[, 53], mtry=4)
pRF <- predict(rfFit, testingSubSet)
confusionMatrix(testingSubSet$classe, pRF)
```


## Cross Validation

Although Random Forest seems to be quite accurate, it can biased without any cross validation.  

```{r results='hide', cache=TRUE}
createFolds(trainingSubSet$classe, k=10)
```

```{r cache=TRUE}
set.seed(4567)
folds <- createFolds(trainingSubSet$classe, k=10)

getConfusionMatrix <- function(fold){
  myTrain <- trainingSubSet[fold, ]
  myCrossValidation <- trainingSubSet[-fold, ]
  
  set.seed(1567)
  fit <- randomForest(myTrain[, -53], myTrain$classe, mtry=4)
  p <- predict(fit, myCrossValidation)
  confusionMatrix(myCrossValidation$classe, p)
}

cm <- data.frame(overall=c(), byclass=c())

acc <- vector()
sens <- vector()
spec <- vector()


for(i in 1:10)
{ 
  cm <- getConfusionMatrix(folds[[i]]) 
  acc <- c(acc, sum(cm$overall["Accuracy"]))
  sens <- c(sens, sum(cm$byClass[, 1]) / 5)
  spec <- c(spec, sum(cm$byClass[, 2]) / 5)
}

paste("Average Accuracy : ", sum(acc)/10)
paste("Average Sensitivity : ", sum(sens)/10)
paste("Average Specificity : ", sum(spec)/10)
```


## Out of sample error

The last step is to try the model on the TestingSubSet that we separated out from the original training set.

```{r cache=TRUE}
fit <- randomForest(trainingSubSet[, -53], trainingSubSet$classe, mtry=4)
pFit <- predict(fit, testingSubSet)
confusionMatrix(testingSubSet$classe, pFit)
```

As it can be seen, it gives an accuracy of about 99.6%.

## Predicting Test Data

inTesting is the test data set that we need to predict for. And we fit the model with the whole unpartitioned training set.


```{r cache=TRUE}
modFit <- randomForest(inTraining[, -53], inTraining$classe, mtry=4)
tFit <- predict(modFit, inTesting)

```

Using the function provided in instructions to generate the output files. 

```{r}
pml_write_files <- function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(tFit)

```
=======

```

partitioning data....

```{r}

```

random forest...

```{r, echo=FALSE}
#rfFit <- randomForest(trainingSubSet[, -53], trainingSubSet[, 53], mtry=4)
##pRF <- predict(rfFit, testingSubSet)
#confusionMatrix(testingSubSet$classe, pRF)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
>>>>>>> master
